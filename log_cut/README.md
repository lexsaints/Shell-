日志切割:
具体场景：服务器产生的日志量非常大，每天将近100M+的日志量，所以博主写了一个日志的分隔脚本；每隔2小时执行一次，当日志文件超过6M时，将日志进行转存，命名格式为20180917-12.log，这样可以防止单个日志文件过大，打开时非常耗CPU,【曾经测试在linux上打开1G的纯文本文件，2G内存 双核虚拟机几乎崩溃，CPU瞬间飚满；在Windows下更打不开】所以将日志进行切割转存，但由于日志量太大，所以要进行定期清除日志，

规则：当所有日志文件超过3G时，删除掉日期最早的日志文件，这样可以保证硬盘空间的相对稳定，也保留最近期的日志文件。具体实现脚本如下：